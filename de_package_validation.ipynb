{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Data Engineering Package Validation\n",
    "\n",
    "This notebook validates packages with robust error handling for complex packages like apache-airflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def check_package_robust(package_name, import_name=None, fallback_imports=None):\n",
    "    \"\"\"Robust package checking with multiple fallback strategies\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    # Strategy 1: Try primary import\n",
    "    try:\n",
    "        module = importlib.import_module(import_name)\n",
    "        \n",
    "        # Try multiple version attributes\n",
    "        version_attrs = ['__version__', 'VERSION', 'version', '_version']\n",
    "        version = 'Unknown'\n",
    "        \n",
    "        for attr in version_attrs:\n",
    "            if hasattr(module, attr):\n",
    "                version_val = getattr(module, attr)\n",
    "                if version_val:\n",
    "                    version = str(version_val)\n",
    "                    break\n",
    "        \n",
    "        return {'status': '‚úÖ', 'version': version, 'method': 'import'}\n",
    "        \n",
    "    except ImportError:\n",
    "        # Strategy 2: Try fallback imports for complex packages\n",
    "        if fallback_imports:\n",
    "            for fallback in fallback_imports:\n",
    "                try:\n",
    "                    module = importlib.import_module(fallback)\n",
    "                    version = getattr(module, '__version__', 'Unknown')\n",
    "                    return {'status': '‚úÖ', 'version': version, 'method': f'fallback: {fallback}'}\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Strategy 3: Check via pip show (package installed but import issues)\n",
    "        try:\n",
    "            result = subprocess.run(['pip', 'show', package_name], \n",
    "                                  capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                for line in result.stdout.split('\\n'):\n",
    "                    if line.startswith('Version:'):\n",
    "                        version = line.split(':', 1)[1].strip()\n",
    "                        return {'status': '‚ö†Ô∏è', 'version': version, 'method': 'pip (import failed)'}\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "        return {'status': '‚ùå', 'version': 'Not Found', 'method': 'not installed'}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'status': '‚ö†Ô∏è', 'version': f'Error: {str(e)[:50]}...', 'method': 'exception'}\n",
    "\n",
    "print(\"üîç Robust Package Validation Starting...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Validation with Fallback Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define packages with their import strategies\n",
    "packages_config = [\n",
    "    # Base packages (already in jupyter/pyspark-notebook)\n",
    "    {'name': 'pyarrow', 'import': 'pyarrow'},\n",
    "    {'name': 'pyspark', 'import': 'pyspark'},\n",
    "    \n",
    "    # Core data processing\n",
    "    {'name': 'boto3', 'import': 'boto3'},\n",
    "    \n",
    "    # Data lake and streaming\n",
    "    {'name': 'deltalake', 'import': 'deltalake'},\n",
    "    {'name': 'kafka-python', 'import': 'kafka'},\n",
    "    {'name': 'minio', 'import': 'minio'},\n",
    "    {'name': 'lakefs-client', 'import': 'lakefs_client'},\n",
    "    \n",
    "    # Data quality and orchestration (complex packages)\n",
    "    {'name': 'great-expectations', 'import': 'great_expectations'},\n",
    "    {'name': 'apache-airflow', 'import': 'airflow', 'fallbacks': ['airflow.version', 'airflow.configuration']},\n",
    "    \n",
    "    # Model serving and deployment\n",
    "    {'name': 'bentoml', 'import': 'bentoml'},\n",
    "    {'name': 'kubeflow-training', 'import': 'kubeflowtraining', 'fallbacks': ['kubeflow.training']},\n",
    "    {'name': 'kubernetes', 'import': 'kubernetes', 'fallbacks': ['kubernetes.client']},\n",
    "    \n",
    "    # Jupyter environment\n",
    "    {'name': 'ipywidgets', 'import': 'ipywidgets'},\n",
    "]\n",
    "\n",
    "print(f\"Checking {len(packages_config)} packages with robust validation...\\n\")\n",
    "\n",
    "results = []\n",
    "for pkg_config in packages_config:\n",
    "    pkg_name = pkg_config['name']\n",
    "    import_name = pkg_config['import']\n",
    "    fallbacks = pkg_config.get('fallbacks', None)\n",
    "    \n",
    "    print(f\"Checking {pkg_name}...\", end=\" \")\n",
    "    result = check_package_robust(pkg_name, import_name, fallbacks)\n",
    "    \n",
    "    results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version'],\n",
    "        'Method': result['method']\n",
    "    })\n",
    "    \n",
    "    print(f\"{result['status']} ({result['method']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "df = pd.DataFrame(results)\n",
    "display(HTML(df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results by status\n",
    "status_counts = df['Status'].value_counts()\n",
    "method_counts = df['Method'].value_counts()\n",
    "\n",
    "print(\"üìä Installation Analysis:\")\n",
    "print(f\"‚úÖ Working: {status_counts.get('‚úÖ', 0)}\")\n",
    "print(f\"‚ö†Ô∏è Issues: {status_counts.get('‚ö†Ô∏è', 0)}\")\n",
    "print(f\"‚ùå Missing: {status_counts.get('‚ùå', 0)}\")\n",
    "\n",
    "total = len(results)\n",
    "success_rate = (status_counts.get('‚úÖ', 0) / total) * 100\n",
    "print(f\"\\nüìà Success Rate: {success_rate:.1f}%\")\n",
    "\n",
    "# Show problematic packages\n",
    "problematic = df[df['Status'] != '‚úÖ']\n",
    "if not problematic.empty:\n",
    "    print(\"\\n‚ö†Ô∏è Packages needing attention:\")\n",
    "    for _, row in problematic.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['Package']}: {row['Version']} ({row['Method']})\")\n",
    "else:\n",
    "    print(\"\\nüéâ All packages are working correctly!\")\n",
    "\n",
    "print(\"\\nüîß Detection Methods Used:\")\n",
    "for method, count in method_counts.items():\n",
    "    print(f\"  ‚Ä¢ {method}: {count} packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality Tests for Complex Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Testing complex package functionality...\\n\")\n",
    "\n",
    "functionality_tests = []\n",
    "\n",
    "# Test Apache Airflow (complex package)\n",
    "print(\"Testing Apache Airflow...\")\n",
    "try:\n",
    "    # Try multiple import strategies\n",
    "    import airflow\n",
    "    from airflow import __version__ as airflow_version\n",
    "    functionality_tests.append(('Apache Airflow', '‚úÖ', f'Core import successful (v{airflow_version})'))\n",
    "    \n",
    "    # Test configuration access\n",
    "    try:\n",
    "        from airflow.configuration import conf\n",
    "        functionality_tests.append(('Airflow Config', '‚úÖ', 'Configuration accessible'))\n",
    "    except Exception as e:\n",
    "        functionality_tests.append(('Airflow Config', '‚ö†Ô∏è', f'Config issue: {str(e)[:40]}...'))\n",
    "        \n",
    "except Exception as e:\n",
    "    functionality_tests.append(('Apache Airflow', '‚ùå', f'Import failed: {str(e)[:40]}...'))\n",
    "\n",
    "# Test Great Expectations\n",
    "print(\"Testing Great Expectations...\")\n",
    "try:\n",
    "    import great_expectations as gx\n",
    "    # Try to create a basic context\n",
    "    functionality_tests.append(('Great Expectations', '‚úÖ', f'Import successful (v{gx.__version__})'))\n",
    "except Exception as e:\n",
    "    functionality_tests.append(('Great Expectations', '‚ùå', f'Failed: {str(e)[:40]}...'))\n",
    "\n",
    "# Test Kubeflow Training\n",
    "print(\"Testing Kubeflow Training...\")\n",
    "try:\n",
    "    import kubeflowtraining\n",
    "    functionality_tests.append(('Kubeflow Training', '‚úÖ', f'Import successful'))\n",
    "    \n",
    "    # Test training module\n",
    "    try:\n",
    "        from kubeflow import training\n",
    "        functionality_tests.append(('Training Module', '‚úÖ', 'Training module accessible'))\n",
    "    except Exception as e:\n",
    "        functionality_tests.append(('Training Module', '‚ö†Ô∏è', f'Module issue: {str(e)[:40]}...'))\n",
    "        \n",
    "except Exception as e:\n",
    "    functionality_tests.append(('Kubeflow Training', '‚ùå', f'Failed: {str(e)[:40]}...'))\n",
    "\n",
    "# Test BentoML\n",
    "print(\"Testing BentoML...\")\n",
    "try:\n",
    "    import bentoml\n",
    "    functionality_tests.append(('BentoML', '‚úÖ', f'Import successful (v{bentoml.__version__})'))\n",
    "except Exception as e:\n",
    "    functionality_tests.append(('BentoML', '‚ùå', f'Failed: {str(e)[:40]}...'))\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "func_df = pd.DataFrame(functionality_tests, columns=['Component', 'Status', 'Result'])\n",
    "display(HTML(func_df.to_html(index=False, escape=False)))\n",
    "\n",
    "print(\"\\n‚ú® Functionality testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"üñ•Ô∏è Environment Information:\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "\n",
    "# Check for Coder environment\n",
    "if os.getenv('CODER_AGENT_TOKEN'):\n",
    "    print(f\"Environment: Coder Workspace\")\n",
    "    print(f\"Workspace: Data Engineering Template\")\n",
    "else:\n",
    "    print(f\"Environment: Standard Jupyter\")\n",
    "\n",
    "print(f\"\\nüì¶ Package Summary:\")\n",
    "print(f\"Total packages checked: {len(results)}\")\n",
    "print(f\"Validation strategies used: {len(method_counts)}\")\n",
    "print(f\"Complex packages handled: apache-airflow, kubeflow-training, kubernetes\")\n",
    "\n",
    "print(f\"\\nüéØ This robust validation handles complex packages with multiple import strategies.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}