{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Workspace Package Validation\n",
    "\n",
    "This notebook validates and displays the versions of all installed packages in your data engineering workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import subprocess\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "def check_package(package_name, import_name=None, version_attr='__version__'):\n",
    "    \"\"\"Check if a package is installed and get its version\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(import_name)\n",
    "        version = getattr(module, version_attr, 'Unknown')\n",
    "        return {'status': '‚úÖ Installed', 'version': version}\n",
    "    except ImportError:\n",
    "        return {'status': '‚ùå Not Found', 'version': 'N/A'}\n",
    "    except Exception as e:\n",
    "        return {'status': '‚ö†Ô∏è Error', 'version': str(e)}\n",
    "\n",
    "def check_package_pip(package_name):\n",
    "    \"\"\"Check package version using pip show\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['pip', 'show', package_name], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if line.startswith('Version:'):\n",
    "                    return line.split(':', 1)[1].strip()\n",
    "        return 'Not Found'\n",
    "    except:\n",
    "        return 'Error'\n",
    "\n",
    "print(\"üîç Validating Data Engineering Workspace Packages...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Data Processing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_packages = [\n",
    "    ('boto3', 'boto3'),\n",
    "    ('duckdb', 'duckdb'),\n",
    "    ('polars', 'polars'),\n",
    "    ('pyarrow', 'pyarrow'),\n",
    "]\n",
    "\n",
    "core_results = []\n",
    "for pkg_name, import_name in core_packages:\n",
    "    result = check_package(pkg_name, import_name)\n",
    "    core_results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version']\n",
    "    })\n",
    "\n",
    "core_df = pd.DataFrame(core_results)\n",
    "display(HTML(core_df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Lake and Streaming Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_packages = [\n",
    "    ('deltalake', 'deltalake'),\n",
    "    ('kafka-python', 'kafka'),\n",
    "    ('minio', 'minio'),\n",
    "    ('lakefs-client', 'lakefs_client'),\n",
    "]\n",
    "\n",
    "data_lake_results = []\n",
    "for pkg_name, import_name in data_lake_packages:\n",
    "    result = check_package(pkg_name, import_name)\n",
    "    data_lake_results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version']\n",
    "    })\n",
    "\n",
    "data_lake_df = pd.DataFrame(data_lake_results)\n",
    "display(HTML(data_lake_df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML and AI Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_packages = [\n",
    "    ('torch', 'torch'),\n",
    "    ('transformers', 'transformers'),\n",
    "    ('datasets', 'datasets'),\n",
    "    ('accelerate', 'accelerate'),\n",
    "    ('mlflow', 'mlflow'),\n",
    "]\n",
    "\n",
    "ml_results = []\n",
    "for pkg_name, import_name in ml_packages:\n",
    "    result = check_package(pkg_name, import_name)\n",
    "    ml_results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version']\n",
    "    })\n",
    "\n",
    "ml_df = pd.DataFrame(ml_results)\n",
    "display(HTML(ml_df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Computing and Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_packages = [\n",
    "    ('ray', 'ray'),\n",
    "    ('apache-airflow', 'airflow'),\n",
    "    ('great-expectations', 'great_expectations'),\n",
    "]\n",
    "\n",
    "distributed_results = []\n",
    "for pkg_name, import_name in distributed_packages:\n",
    "    result = check_package(pkg_name, import_name)\n",
    "    distributed_results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version']\n",
    "    })\n",
    "\n",
    "distributed_df = pd.DataFrame(distributed_results)\n",
    "display(HTML(distributed_df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Serving and Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_packages = [\n",
    "    ('pymilvus', 'pymilvus'),\n",
    "    ('bentoml', 'bentoml'),\n",
    "    ('kfp', 'kfp'),\n",
    "    ('kubernetes', 'kubernetes'),\n",
    "]\n",
    "\n",
    "serving_results = []\n",
    "for pkg_name, import_name in serving_packages:\n",
    "    result = check_package(pkg_name, import_name)\n",
    "    serving_results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version']\n",
    "    })\n",
    "\n",
    "serving_df = pd.DataFrame(serving_results)\n",
    "display(HTML(serving_df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_packages = [\n",
    "    ('ipywidgets', 'ipywidgets'),\n",
    "    ('jupyterlab', 'jupyterlab'),\n",
    "]\n",
    "\n",
    "jupyter_results = []\n",
    "for pkg_name, import_name in jupyter_packages:\n",
    "    result = check_package(pkg_name, import_name)\n",
    "    jupyter_results.append({\n",
    "        'Package': pkg_name,\n",
    "        'Status': result['status'],\n",
    "        'Version': result['version']\n",
    "    })\n",
    "\n",
    "jupyter_df = pd.DataFrame(jupyter_results)\n",
    "display(HTML(jupyter_df.to_html(index=False, escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = core_results + data_lake_results + ml_results + distributed_results + serving_results + jupyter_results\n",
    "\n",
    "# Count status\n",
    "installed_count = sum(1 for r in all_results if '‚úÖ' in r['Status'])\n",
    "not_found_count = sum(1 for r in all_results if '‚ùå' in r['Status'])\n",
    "error_count = sum(1 for r in all_results if '‚ö†Ô∏è' in r['Status'])\n",
    "total_count = len(all_results)\n",
    "\n",
    "print(f\"üìä Package Installation Summary:\")\n",
    "print(f\"‚úÖ Successfully Installed: {installed_count}/{total_count}\")\n",
    "print(f\"‚ùå Not Found: {not_found_count}/{total_count}\")\n",
    "print(f\"‚ö†Ô∏è Errors: {error_count}/{total_count}\")\n",
    "print(f\"\\nüìà Success Rate: {(installed_count/total_count)*100:.1f}%\")\n",
    "\n",
    "if not_found_count > 0 or error_count > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Issues found with some packages. Check the tables above for details.\")\n",
    "else:\n",
    "    print(\"\\nüéâ All packages are successfully installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"üñ•Ô∏è System Information:\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "\n",
    "# Check if we're in a Jupyter environment\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    if get_ipython() is not None:\n",
    "        print(f\"Environment: Jupyter Notebook/Lab\")\n",
    "except:\n",
    "    print(f\"Environment: Standard Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Package Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Running quick functionality tests...\\n\")\n",
    "\n",
    "# Test core packages with simple operations\n",
    "tests = []\n",
    "\n",
    "# Test DuckDB\n",
    "try:\n",
    "    import duckdb\n",
    "    result = duckdb.sql(\"SELECT 'DuckDB working!' as test\").fetchone()\n",
    "    tests.append(('DuckDB', '‚úÖ SQL query successful'))\n",
    "except Exception as e:\n",
    "    tests.append(('DuckDB', f'‚ùå {str(e)[:50]}...'))\n",
    "\n",
    "# Test Polars\n",
    "try:\n",
    "    import polars as pl\n",
    "    df = pl.DataFrame({'test': [1, 2, 3]})\n",
    "    tests.append(('Polars', '‚úÖ DataFrame creation successful'))\n",
    "except Exception as e:\n",
    "    tests.append(('Polars', f'‚ùå {str(e)[:50]}...'))\n",
    "\n",
    "# Test PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    tensor = torch.tensor([1, 2, 3])\n",
    "    tests.append(('PyTorch', '‚úÖ Tensor creation successful'))\n",
    "except Exception as e:\n",
    "    tests.append(('PyTorch', f'‚ùå {str(e)[:50]}...'))\n",
    "\n",
    "# Test Ray\n",
    "try:\n",
    "    import ray\n",
    "    tests.append(('Ray', '‚úÖ Import successful'))\n",
    "except Exception as e:\n",
    "    tests.append(('Ray', f'‚ùå {str(e)[:50]}...'))\n",
    "\n",
    "# Display test results\n",
    "test_df = pd.DataFrame(tests, columns=['Package', 'Test Result'])\n",
    "display(HTML(test_df.to_html(index=False, escape=False)))\n",
    "\n",
    "print(\"\\n‚ú® Package validation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}